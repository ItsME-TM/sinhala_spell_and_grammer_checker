{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 535ms/step\n",
      "1/1 [==============================] - 1s 966ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences:  17%|█▋        | 1/6 [00:04<00:20,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences:  33%|███▎      | 2/6 [00:07<00:15,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences:  50%|█████     | 3/6 [00:09<00:08,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences:  67%|██████▋   | 4/6 [00:12<00:05,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences:  83%|████████▎ | 5/6 [00:14<00:02,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Sentences: 100%|██████████| 6/6 [00:18<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the LSTM models\n",
    "lstm_model = load_model('Models/LSTM_Model/lstm_sinhala_grammar_checker.h5')\n",
    "advanced_lstm_model = load_model('Models/Advanced_LSTM/advanced_lstm_sinhala_grammar_checker.h5')\n",
    "\n",
    "# Load the BART model and tokenizer\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('Models/Advanced_Bart/bart_sinhala_grammar_checker')\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('Models/Advanced_Bart/bart_sinhala_grammar_checker')\n",
    "\n",
    "# Initialize the Keras Tokenizer \n",
    "lstm_tokenizer = Tokenizer()\n",
    "training_data = [\n",
    "    \"මම ගමට යමි\", \"ඔහු පාසලට ගියේය\", \"අපි ගඟේ දිය නෑවෙමු\", \"ඔවුන් විභාගය ජයග්‍රහණය කළහ\"\n",
    "]\n",
    "lstm_tokenizer.fit_on_texts(training_data)\n",
    "\n",
    "def test_lstm(model, tokenizer, sentence):\n",
    "    # Get the expected input shape from the model\n",
    "    max_len = model.input_shape[1]  \n",
    "    \n",
    "    # Tokenize and pad the sentence\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_sequence = np.argmax(prediction, axis=-1)\n",
    "    \n",
    "    # Decode the predicted sequence\n",
    "    corrected_sentence = tokenizer.sequences_to_texts([predicted_sequence[0]])\n",
    "    return corrected_sentence[0]\n",
    "\n",
    "\n",
    "# Define the BART testing function\n",
    "def test_bart(model, tokenizer, sentence, max_len=128):\n",
    "    input_text = \"grammar_error: \" + sentence\n",
    "    input_encoding = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n",
    "    outputs = model.generate(input_encoding[\"input_ids\"], max_length=max_len, num_beams=4, early_stopping=True)\n",
    "    corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return corrected_sentence\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"මම යනවා\",  \n",
    "    \"ඔහු පාසලට ගිහින් නැහැ\",  \n",
    "    \"අපි නෑවෙ\",  \n",
    "    \"ඔවුන් විභාගය ජයග්‍රහණය කළ\",\n",
    "    \"අපි යැවෙයි\",\n",
    "    \"අපි බත් කමින් ගෙදර යැවෙයි\"\n",
    "]\n",
    "\n",
    "# Compare models\n",
    "results = []\n",
    "for sentence in tqdm(test_sentences, desc=\"Testing Sentences\"):\n",
    "    start_time = time.time()\n",
    "    lstm_output = test_lstm(lstm_model, lstm_tokenizer, sentence)\n",
    "    lstm_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    advanced_lstm_output = test_lstm(advanced_lstm_model, lstm_tokenizer, sentence)\n",
    "    advanced_lstm_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    bart_output = test_bart(bart_model, bart_tokenizer, sentence)\n",
    "    bart_time = time.time() - start_time\n",
    "\n",
    "    results.append({\n",
    "        \"Original Sentence\": sentence,\n",
    "        \"LSTM Output\": lstm_output,\n",
    "        \"LSTM Time (s)\": lstm_time,\n",
    "        \"LSTM + Attention Output\": advanced_lstm_output,\n",
    "        \"LSTM + Attention Time (s)\": advanced_lstm_time,\n",
    "        \"BART Output\": bart_output,\n",
    "        \"BART Time (s)\": bart_time,\n",
    "    })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'model_comparison_results/comparison_results.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Sentence</th>\n",
       "      <th>LSTM Output</th>\n",
       "      <th>LSTM Time (s)</th>\n",
       "      <th>LSTM + Attention Output</th>\n",
       "      <th>LSTM + Attention Time (s)</th>\n",
       "      <th>BART Output</th>\n",
       "      <th>BART Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>මම යනවා</td>\n",
       "      <td>මම</td>\n",
       "      <td>0.599059</td>\n",
       "      <td>මම</td>\n",
       "      <td>1.019694</td>\n",
       "      <td>අපි යැවෙමු</td>\n",
       "      <td>2.436017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ඔහු පාසලට ගිහින් නැහැ</td>\n",
       "      <td>පාසලට නෑවෙමු</td>\n",
       "      <td>0.097513</td>\n",
       "      <td>ඔහු පාසලට</td>\n",
       "      <td>0.215059</td>\n",
       "      <td>ඔහු පාසලට ොිව්නීය</td>\n",
       "      <td>3.339802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>අපි නෑවෙ</td>\n",
       "      <td></td>\n",
       "      <td>0.110039</td>\n",
       "      <td>අපි</td>\n",
       "      <td>0.324612</td>\n",
       "      <td>අපි නැවෙමු</td>\n",
       "      <td>1.289956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ඔවුන් විභාගය ජයග්‍රහණය කළ</td>\n",
       "      <td>නෑවෙමු මම ජයග්‍රහණය</td>\n",
       "      <td>0.079003</td>\n",
       "      <td>ඔවුන් විභාගය ජයග්‍රහණය</td>\n",
       "      <td>0.110041</td>\n",
       "      <td>ඔවුන් ළමය ගෙදර අපිලා</td>\n",
       "      <td>2.880533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>අපි යැවෙයි</td>\n",
       "      <td></td>\n",
       "      <td>0.082515</td>\n",
       "      <td>අපි</td>\n",
       "      <td>0.306373</td>\n",
       "      <td>අපි යැවෙමු</td>\n",
       "      <td>1.395645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Original Sentence          LSTM Output  LSTM Time (s)  \\\n",
       "0                    මම යනවා                   මම       0.599059   \n",
       "1      ඔහු පාසලට ගිහින් නැහැ         පාසලට නෑවෙමු       0.097513   \n",
       "2                   අපි නෑවෙ                            0.110039   \n",
       "3  ඔවුන් විභාගය ජයග්‍රහණය කළ  නෑවෙමු මම ජයග්‍රහණය       0.079003   \n",
       "4                 අපි යැවෙයි                            0.082515   \n",
       "\n",
       "  LSTM + Attention Output  LSTM + Attention Time (s)           BART Output  \\\n",
       "0                      මම                   1.019694            අපි යැවෙමු   \n",
       "1               ඔහු පාසලට                   0.215059     ඔහු පාසලට ොිව්නීය   \n",
       "2                     අපි                   0.324612            අපි නැවෙමු   \n",
       "3  ඔවුන් විභාගය ජයග්‍රහණය                   0.110041  ඔවුන් ළමය ගෙදර අපිලා   \n",
       "4                     අපි                   0.306373            අපි යැවෙමු   \n",
       "\n",
       "   BART Time (s)  \n",
       "0       2.436017  \n",
       "1       3.339802  \n",
       "2       1.289956  \n",
       "3       2.880533  \n",
       "4       1.395645  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "# Save results to a CSV\n",
    "results_csv_path = \"model_comparison_results/comparison_results.csv\"\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "# Display the content of the CSV\n",
    "print(f\"Results saved to '{results_csv_path}'\")\n",
    "results_df.head()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
