{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 53s 247ms/step - loss: 1.0845 - accuracy: 0.6951 - val_loss: 0.2675 - val_accuracy: 0.9123\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 47s 257ms/step - loss: 0.1775 - accuracy: 0.9379 - val_loss: 0.1045 - val_accuracy: 0.9595\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 45s 247ms/step - loss: 0.0881 - accuracy: 0.9636 - val_loss: 0.0694 - val_accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 44s 244ms/step - loss: 0.0615 - accuracy: 0.9718 - val_loss: 0.0599 - val_accuracy: 0.9738\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 44s 245ms/step - loss: 0.0474 - accuracy: 0.9766 - val_loss: 0.0534 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 44s 244ms/step - loss: 0.0377 - accuracy: 0.9798 - val_loss: 0.0492 - val_accuracy: 0.9775\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 44s 240ms/step - loss: 0.0343 - accuracy: 0.9800 - val_loss: 0.0513 - val_accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 44s 245ms/step - loss: 0.0320 - accuracy: 0.9813 - val_loss: 0.0469 - val_accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 44s 242ms/step - loss: 0.0320 - accuracy: 0.9815 - val_loss: 0.0502 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 46s 252ms/step - loss: 0.0303 - accuracy: 0.9827 - val_loss: 0.0507 - val_accuracy: 0.9795\n",
      "1/1 [==============================] - 1s 903ms/step\n",
      "Corrected Sentence: මම ගමට වාහන කළේය කළේය කළේය කළේය\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Dropout, Attention\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = 'Dataset/sinhala_dataset.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Prepare data\n",
    "input_texts = data['grammar_error_sentence'].values\n",
    "target_texts = data['corrected_sentence'].values\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_texts + target_texts)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "# Padding sequences\n",
    "max_seq_len = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in target_sequences))\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_seq_len, padding='post')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_sequences, target_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 1024\n",
    "lstm_units = 1024\n",
    "\n",
    "# Define the model\n",
    "inputs = Input(shape=(max_seq_len,))\n",
    "x = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs)\n",
    "x = Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "attention = Attention()([x, x])  \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Concatenate()([x, attention]) \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)\n",
    "\n",
    "# Save the model\n",
    "model.save('Models/Advanced_LSTM/advanced_lstm_sinhala_grammar_checker.h5')\n",
    "\n",
    "# Example prediction function\n",
    "def correct_sentence(input_sentence):\n",
    "    sequence = tokenizer.texts_to_sequences([input_sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_seq_len, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_sequence = np.argmax(prediction, axis=-1)[0]\n",
    "    corrected_sentence = tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
    "    return corrected_sentence\n",
    "\n",
    "# Test the model\n",
    "test_sentence = \"මම ගමට යනවා\"\n",
    "print(\"Corrected Sentence:\", correct_sentence(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 360ms/step\n",
      "Corrected Sentence: වාහන ඔහුගෙන් පොතක් කළේය කළේය කළේය කළේය\n"
     ]
    }
   ],
   "source": [
    "# Example prediction function\n",
    "def correct_sentence(input_sentence):\n",
    "    sequence = tokenizer.texts_to_sequences([input_sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_seq_len, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_sequence = np.argmax(prediction, axis=-1)[0]\n",
    "    corrected_sentence = tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
    "    return corrected_sentence\n",
    "\n",
    "# Test the model\n",
    "test_sentence = \"මම ඔහුගෙන් පොතක් දෙන්නෙමු\"\n",
    "print(\"Corrected Sentence:\", correct_sentence(test_sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
